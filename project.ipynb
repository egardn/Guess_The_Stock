{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, GRU, Concatenate, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# 1Ô∏è‚É£ Load & Cache Data Efficiently\n",
    "# ----------------------------------\n",
    "if os.path.exists('X_train.pkl') and os.path.exists('y_train.pkl'):\n",
    "    X_train = pd.read_pickle('X_train.pkl')\n",
    "    y_train = pd.read_pickle('y_train.pkl')\n",
    "else:\n",
    "    X_train = pd.read_csv('X_train_N1UvY30.csv')\n",
    "    y_train = pd.read_csv('y_train_or6m3Ta.csv')\n",
    "    X_train.to_pickle('X_train.pkl')\n",
    "    y_train.to_pickle('y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 2Ô∏è‚É£ Custom Transformer: Time Step Reshaper (No changes needed)\n",
    "# ----------------------------------\n",
    "class TimeStepReshaper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to reshape data into observations of time steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, time_steps=100):\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        num_samples = X.shape[0] // self.time_steps\n",
    "        reshaped_X = X.iloc[:num_samples * self.time_steps].values.reshape(num_samples, self.time_steps, -1)\n",
    "        return reshaped_X\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# 3Ô∏è‚É£ Custom Transformer: OrdinalEncoderTransformer (No changes needed)\n",
    "# ----------------------------------\n",
    "class OrdinalEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to apply Ordinal Encoding on categorical features.\n",
    "    Stores encoders and vocabulary sizes.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        self.vocabulary_sizes = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoders = {col: OrdinalEncoder() for col in X.columns}\n",
    "        self.vocabulary_sizes = {}\n",
    "        for col, encoder in self.encoders.items():\n",
    "            encoder.fit(X[[col]])\n",
    "            self.vocabulary_sizes[col] = len(encoder.categories_[0])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        encoded_features = np.column_stack(\n",
    "            [self.encoders[col].transform(X[[col]]).astype(int) for col in X.columns]\n",
    "        )\n",
    "        return encoded_features\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# 4Ô∏è‚É£ Custom Transformer: TensorFlowStockClassifier (Modified for cleaner fit)\n",
    "# ----------------------------------\n",
    "class TensorFlowStockClassifier(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom Transformer for TensorFlow model.\n",
    "    Vocabulary sizes are now determined within the pipeline's fit process.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim=8, lstm_units=64, epochs=10, batch_size=128, cat_feature_names=None, num_feature_names=None):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary_sizes = None  # Vocabulary sizes will be set in fit\n",
    "        self.cat_feature_names = cat_feature_names\n",
    "        self.num_feature_names = num_feature_names\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build and train the TensorFlow model.\n",
    "        Vocabulary sizes are extracted from the fitted preprocessor.\n",
    "        \"\"\"\n",
    "        time_steps = X.shape[1]\n",
    "        num_features = X.shape[2]\n",
    "        num_cats = len(self.cat_feature_names)\n",
    "        num_numerical = len(self.num_feature_names)\n",
    "\n",
    "        # üåü Get vocabulary sizes from the fitted preprocessor in the pipeline\n",
    "        ordinal_encoder_transformer = self.pipeline_.named_steps['preprocessor'].named_transformers_['cat'].named_steps['encoder']\n",
    "        self.vocabulary_sizes = ordinal_encoder_transformer.vocabulary_sizes\n",
    "\n",
    "\n",
    "        # Define input layers\n",
    "        categorical_input = Input(shape=(time_steps, num_cats), dtype=tf.int32, name='categorical_input')\n",
    "        numerical_input = Input(shape=(time_steps, num_numerical), name='numerical_input')\n",
    "\n",
    "        # Embedding Layers\n",
    "        venue_embedding = TimeDistributed(Flatten())(TimeDistributed(Embedding(self.vocabulary_sizes['venue'], self.embedding_dim))(categorical_input[:,:, 0:1]))\n",
    "        action_embedding = TimeDistributed(Flatten())(TimeDistributed(Embedding(self.vocabulary_sizes['action'], self.embedding_dim))(categorical_input[:,:, 1:2]))\n",
    "        trade_embedding = TimeDistributed(Flatten())(TimeDistributed(Embedding(self.vocabulary_sizes['trade'], self.embedding_dim))(categorical_input[:,:, 2:3]))\n",
    "\n",
    "        # Merge inputs\n",
    "        merged_inputs = Concatenate(axis=-1)([venue_embedding, action_embedding, trade_embedding, numerical_input])\n",
    "\n",
    "        # GRU layers\n",
    "        gru_forward = GRU(self.lstm_units, return_sequences=True)(merged_inputs)\n",
    "        gru_backward = GRU(self.lstm_units, return_sequences=True, go_backwards=True)(merged_inputs)\n",
    "        gru_output = Concatenate()([gru_forward, gru_backward])\n",
    "        flattened_gru_output = Flatten()(gru_output)\n",
    "\n",
    "        # Dense layers for classification\n",
    "        dense1 = Dense(64, activation='selu')(flattened_gru_output)\n",
    "        output = Dense(24, activation='softmax')(dense1)\n",
    "\n",
    "        # Define and compile model\n",
    "        self.model = Model(inputs=[categorical_input, numerical_input], outputs=output)\n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Prepare input data (assuming preprocessed by ColumnTransformer)\n",
    "        X_cat_train = X[:, :, :num_cats]\n",
    "        X_num_train = X[:, :, num_cats:]\n",
    "\n",
    "        # Train model\n",
    "        self.model.fit([X_cat_train, X_num_train], y, epochs=self.epochs, batch_size=self.batch_size, verbose=1)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        num_cats = len(self.cat_feature_names)\n",
    "        X_cat_test = X[:, :, :num_cats]\n",
    "        X_num_test = X[:, :, num_cats:]\n",
    "        return self.model.predict([X_cat_test, X_num_test])\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# 5Ô∏è‚É£ Define Preprocessing Pipeline (No changes needed)\n",
    "# ----------------------------------\n",
    "cat_features = ['venue', 'action', 'trade']\n",
    "num_features = ['bid', 'ask', 'price', 'bid_size', 'ask_size', 'flux']\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    ('encoder', OrdinalEncoderTransformer())\n",
    "])\n",
    "\n",
    "numerical_preprocessor = Pipeline([\n",
    "    ('passthrough', 'passthrough')\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_preprocessor, cat_features),\n",
    "        ('num', numerical_preprocessor, num_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# 6Ô∏è‚É£ Full Pipeline (Clean and Integrated Fit)\n",
    "# ----------------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('reshape', TimeStepReshaper(time_steps=100)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', TensorFlowStockClassifier(\n",
    "        embedding_dim=8, lstm_units=64, epochs=10, batch_size=128,\n",
    "        cat_feature_names=cat_features,\n",
    "        num_feature_names=num_features\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train Pipeline (Now much cleaner!)\n",
    "X_train_reshaped_np = TimeStepReshaper(time_steps=100).fit_transform(X_train) # Reshape to numpy array\n",
    "\n",
    "# Convert reshaped numpy array back to DataFrame for ColumnTransformer\n",
    "original_columns = X_train.columns # Get original column names\n",
    "num_original_columns = len(original_columns)\n",
    "X_train_reshaped = pd.DataFrame(\n",
    "    X_train_reshaped_np.reshape(-1, num_original_columns), # Flatten back to 2D and then reshape to DataFrame\n",
    "    columns=original_columns\n",
    ").groupby(np.arange(len(X_train_reshaped_np.reshape(-1, num_original_columns))) // 100).apply(lambda x: x.values.reshape(100, num_original_columns)) # Reshape back to 3D DataFrame\n",
    "\n",
    "\n",
    "pipeline.fit(X_train_reshaped, y_train.iloc[:X_train_reshaped.shape[0]]) # Fit the pipeline\n",
    "\n",
    "\n",
    "# To predict (example)\n",
    "# predictions = pipeline.predict(X_test) # Assuming X_test is loaded and in original format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
